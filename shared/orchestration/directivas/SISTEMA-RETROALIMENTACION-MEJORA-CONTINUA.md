# SISTEMA DE RETROALIMENTACI√ìN Y MEJORA CONTINUA

**Proyecto:** MVP Sistema Administraci√≥n de Obra e INFONAVIT
**Versi√≥n:** 1.0.0
**Fecha:** 2025-11-17
**Audiencia:** Agentes Principales y administradores del sistema

---

## PROP√ìSITO

Este documento establece el **sistema de retroalimentaci√≥n** que permite:

1. **Capturar** errores y problemas de subagentes de forma estructurada
2. **Analizar** patrones de errores sistem√°ticos
3. **Identificar** causas ra√≠z comunes
4. **Mejorar** prompts, directivas y templates bas√°ndose en datos reales
5. **Medir** efectividad de las mejoras implementadas

**Objetivo:** Crear un ciclo de mejora continua que reduzca progresivamente los errores de subagentes y aumente su eficiencia.

---

## ARQUITECTURA DEL SISTEMA

```mermaid
graph TD
    A[Subagente completa tarea] --> B[Agente Principal valida]
    B --> C{¬øAprobado?}
    C -->|S√ç| D[Registrar √©xito]
    C -->|NO| E[Registrar error en JSONL]
    E --> F[Subagente corrige]
    F --> B
    D --> G[Actualizar m√©tricas]
    E --> G
    G --> H{¬ø20+ validaciones?}
    H -->|S√ç| I[Analizar patrones]
    H -->|NO| J[Continuar]
    I --> K{¬øPatr√≥n detectado?}
    K -->|S√ç| L[Identificar causa ra√≠z]
    K -->|NO| J
    L --> M[Actualizar prompt/directiva]
    M --> N[Documentar mejora]
    N --> O[Medir efectividad]
    O --> J
```

---

## COMPONENTE 1: CAPTURA DE FEEDBACK

### 1.1. Archivo de Feedback

**Ubicaci√≥n:** `orchestration/estados/FEEDBACK-SUBAGENTES.jsonl`

**Formato:** JSONL (JSON Lines) - una l√≠nea por error

**Estructura de cada entrada:**

```json
{
  "timestamp": "2025-11-17T14:30:00Z",
  "subagent": "general-purpose-001",
  "task_id": "DB-042-SUB-001",
  "agent_principal": "Database-Agent",
  "error_category": "missing_specification",
  "error_detail": "Falt√≥ implementar √≠ndice idx_projects_code especificado en contexto",
  "phase": "validation_technical",
  "archivo_afectado": "apps/database/ddl/schemas/project_management/tables/01-projects.sql",
  "corrected": true,
  "iterations": 2,
  "time_to_fix_minutes": 15,
  "context_provided": true,
  "reference_consulted": true,
  "inventory_checked": false
}
```

**Campos obligatorios:**

```yaml
timestamp:              # ISO 8601 timestamp del error
subagent:               # ID o tipo del subagente
task_id:                # ID de la tarea (ej: DB-042-SUB-001)
agent_principal:        # Agente que valid√≥ (Database-Agent, Backend-Agent, etc.)
error_category:         # Categor√≠a estandarizada del error (ver 1.2)
error_detail:           # Descripci√≥n espec√≠fica del error
phase:                  # Fase donde se detect√≥ (ver 1.3)
archivo_afectado:       # Archivo donde ocurri√≥ el error (si aplica)
corrected:              # true/false - ¬øSe corrigi√≥ el error?
iterations:             # N√∫mero de intentos hasta correcci√≥n o abandono
time_to_fix_minutes:    # Tiempo en minutos para corregir
context_provided:       # ¬øSe proporcion√≥ contexto completo al subagente?
reference_consulted:    # ¬øSubagente consult√≥ referencias?
inventory_checked:      # ¬øSubagente verific√≥ inventarios?
```

### 1.2. Categor√≠as de Errores Estandarizadas

```yaml
# Errores de Reporte
incomplete_report:           # Reporte sin secciones obligatorias
missing_validation_output:   # No incluy√≥ outputs de comandos de validaci√≥n
no_report:                   # No gener√≥ reporte

# Errores T√©cnicos
syntax_error:                # Error de sintaxis (SQL, TypeScript, etc.)
build_error:                 # C√≥digo no compila
runtime_error:               # Error en ejecuci√≥n
type_error:                  # Error de tipos TypeScript
import_error:                # Imports incorrectos o faltantes

# Errores de Especificaci√≥n
missing_specification:       # Falt√≥ implementar elemento solicitado
wrong_specification:         # Implement√≥ diferente a lo solicitado
extra_elements:             # Agreg√≥ elementos no solicitados
incomplete_implementation:   # Implementaci√≥n parcial

# Errores de Convenciones
wrong_nomenclature:          # Nombres incorrectos (no siguen est√°ndares)
wrong_location:              # Archivos en ubicaci√≥n incorrecta
wrong_structure:             # Estructura de c√≥digo incorrecta
wrong_file_name:             # Nombre de archivo incorrecto

# Errores de Documentaci√≥n
inventory_not_updated:       # No actualiz√≥ inventario
trace_not_updated:           # No actualiz√≥ traza
incomplete_documentation:    # Documentaci√≥n incompleta o incorrecta
wrong_inventory_format:      # Formato incorrecto en inventario

# Errores de Anti-Duplicaci√≥n
duplicate_created:           # Cre√≥ un objeto duplicado
duplicate_not_detected:      # No detect√≥ duplicado existente
wrong_search:                # B√∫squeda anti-duplicaci√≥n insuficiente o incorrecta

# Errores de Contexto
context_not_read:            # No ley√≥ archivos de contexto proporcionados
reference_not_consulted:     # No consult√≥ templates/referencias
assumption_made:             # Asumi√≥ valores no especificados sin preguntar
misunderstood_context:       # Malinterpret√≥ el contexto proporcionado

# Errores de Proceso
skipped_validation:          # No ejecut√≥ validaciones antes de reportar
wrong_validation:            # Ejecut√≥ validaciones incorrectas
no_questions_asked:          # No pregunt√≥ cuando contexto insuficiente
premature_report:            # Report√≥ antes de completar

# Errores de Orchestration
orchestration_folder_wrong_place: # Cre√≥ carpeta orchestration/ en lugar incorrecto
modified_unspecified_files:       # Modific√≥ archivos no especificados
ignored_restrictions:             # Ignor√≥ restricciones expl√≠citas
```

### 1.3. Fases de Detecci√≥n

```yaml
validation_report:       # Error detectado al revisar reporte
validation_technical:    # Error detectado en validaci√≥n t√©cnica (compilaci√≥n, ejecuci√≥n)
validation_specs:        # Error detectado al verificar especificaciones
validation_conventions:  # Error detectado al verificar convenciones
validation_docs:         # Error detectado al verificar documentaci√≥n
anti_duplication:        # Error detectado al verificar duplicados
execution:               # Error durante ejecuci√≥n de tarea (antes de reportar)
```

### 1.4. Registrar Feedback (Agente Principal)

**Cuando detectes un error durante validaci√≥n:**

```bash
# Agregar entrada al archivo JSONL
cat >> orchestration/estados/FEEDBACK-SUBAGENTES.jsonl << 'EOF'
{"timestamp":"2025-11-17T14:30:00Z","subagent":"general-purpose-001","task_id":"DB-042-SUB-001","agent_principal":"Database-Agent","error_category":"missing_specification","error_detail":"Falt√≥ implementar √≠ndice idx_projects_code especificado en contexto","phase":"validation_technical","archivo_afectado":"apps/database/ddl/schemas/project_management/tables/01-projects.sql","corrected":true,"iterations":2,"time_to_fix_minutes":15,"context_provided":true,"reference_consulted":false,"inventory_checked":true}
EOF
```

**Campos a registrar:**

```markdown
**Siempre registrar:**
- timestamp (ISO 8601)
- subagent (tipo o ID)
- task_id
- agent_principal (tu nombre)
- error_category (de la lista estandarizada)
- error_detail (descripci√≥n espec√≠fica)
- phase (d√≥nde se detect√≥)
- corrected (true si se corrigi√≥, false si se abandon√≥)
- iterations (cu√°ntos intentos)

**Si es aplicable:**
- archivo_afectado (ruta del archivo con error)
- time_to_fix_minutes (tiempo que tom√≥ corregir)
- context_provided (¬øle diste contexto completo?)
- reference_consulted (¬øconsult√≥ templates?)
- inventory_checked (¬øverific√≥ inventarios?)
```

---

## COMPONENTE 2: AN√ÅLISIS DE PATRONES

### 2.1. Frecuencia de An√°lisis

**Ejecutar an√°lisis:**
- Cada 20 validaciones completadas
- Semanalmente (si hay actividad)
- Mensualmente (an√°lisis completo)

### 2.2. Script de An√°lisis

**Ubicaci√≥n:** `orchestration/scripts/analyze-feedback.sh`

```bash
#!/bin/bash

# Script para analizar feedback de subagentes
# Uso: ./analyze-feedback.sh [--last N] [--category CATEGORY]

FEEDBACK_FILE="orchestration/estados/FEEDBACK-SUBAGENTES.jsonl"
OUTPUT_DIR="orchestration/reportes/analisis-feedback"

# Crear directorio de salida
mkdir -p "$OUTPUT_DIR"

TIMESTAMP=$(date +%Y%m%d_%H%M%S)
REPORT_FILE="$OUTPUT_DIR/analisis-$TIMESTAMP.md"

echo "# AN√ÅLISIS DE FEEDBACK - $TIMESTAMP" > "$REPORT_FILE"
echo "" >> "$REPORT_FILE"
echo "Generado: $(date --iso-8601=seconds)" >> "$REPORT_FILE"
echo "" >> "$REPORT_FILE"

# 1. Estad√≠sticas generales
echo "## 1. ESTAD√çSTICAS GENERALES" >> "$REPORT_FILE"
echo "" >> "$REPORT_FILE"

TOTAL_ERRORS=$(wc -l < "$FEEDBACK_FILE")
echo "- **Total de errores registrados:** $TOTAL_ERRORS" >> "$REPORT_FILE"

CORRECTED=$(jq -r 'select(.corrected == true)' "$FEEDBACK_FILE" | wc -l)
NOT_CORRECTED=$(jq -r 'select(.corrected == false)' "$FEEDBACK_FILE" | wc -l)
echo "- **Errores corregidos:** $CORRECTED ($((CORRECTED * 100 / TOTAL_ERRORS))%)" >> "$REPORT_FILE"
echo "- **Errores no corregidos:** $NOT_CORRECTED ($((NOT_CORRECTED * 100 / TOTAL_ERRORS))%)" >> "$REPORT_FILE"

AVG_ITERATIONS=$(jq -r '.iterations' "$FEEDBACK_FILE" | awk '{sum+=$1; count++} END {printf "%.2f", sum/count}')
echo "- **Promedio de iteraciones:** $AVG_ITERATIONS" >> "$REPORT_FILE"

echo "" >> "$REPORT_FILE"

# 2. Top 10 categor√≠as de errores
echo "## 2. TOP 10 CATEGOR√çAS DE ERRORES" >> "$REPORT_FILE"
echo "" >> "$REPORT_FILE"
echo "| Categor√≠a | Frecuencia | % | Promedio Iteraciones |" >> "$REPORT_FILE"
echo "|-----------|------------|---|----------------------|" >> "$REPORT_FILE"

jq -r '.error_category' "$FEEDBACK_FILE" | sort | uniq -c | sort -rn | head -10 | while read count category; do
    percentage=$((count * 100 / TOTAL_ERRORS))
    avg_iter=$(jq -r "select(.error_category == \"$category\") | .iterations" "$FEEDBACK_FILE" | awk '{sum+=$1; cnt++} END {printf "%.1f", sum/cnt}')
    echo "| $category | $count | $percentage% | $avg_iter |" >> "$REPORT_FILE"
done

echo "" >> "$REPORT_FILE"

# 3. Errores por fase
echo "## 3. ERRORES POR FASE DE DETECCI√ìN" >> "$REPORT_FILE"
echo "" >> "$REPORT_FILE"
echo "| Fase | Frecuencia | % |" >> "$REPORT_FILE"
echo "|------|------------|---|" >> "$REPORT_FILE"

jq -r '.phase' "$FEEDBACK_FILE" | sort | uniq -c | sort -rn | while read count phase; do
    percentage=$((count * 100 / TOTAL_ERRORS))
    echo "| $phase | $count | $percentage% |" >> "$REPORT_FILE"
done

echo "" >> "$REPORT_FILE"

# 4. Errores por agente principal
echo "## 4. ERRORES POR AGENTE PRINCIPAL" >> "$REPORT_FILE"
echo "" >> "$REPORT_FILE"
echo "| Agente | Frecuencia | % | Promedio Iteraciones |" >> "$REPORT_FILE"
echo "|--------|------------|---|----------------------|" >> "$REPORT_FILE"

jq -r '.agent_principal' "$FEEDBACK_FILE" | sort | uniq -c | sort -rn | while read count agent; do
    percentage=$((count * 100 / TOTAL_ERRORS))
    avg_iter=$(jq -r "select(.agent_principal == \"$agent\") | .iterations" "$FEEDBACK_FILE" | awk '{sum+=$1; cnt++} END {printf "%.1f", sum/cnt}')
    echo "| $agent | $count | $percentage% | $avg_iter |" >> "$REPORT_FILE"
done

echo "" >> "$REPORT_FILE"

# 5. An√°lisis de contexto
echo "## 5. AN√ÅLISIS DE CONTEXTO PROPORCIONADO" >> "$REPORT_FILE"
echo "" >> "$REPORT_FILE"

CONTEXT_YES=$(jq -r 'select(.context_provided == true)' "$FEEDBACK_FILE" | wc -l)
CONTEXT_NO=$(jq -r 'select(.context_provided == false)' "$FEEDBACK_FILE" | wc -l)
echo "- **Contexto proporcionado:** $CONTEXT_YES ($((CONTEXT_YES * 100 / TOTAL_ERRORS))%)" >> "$REPORT_FILE"
echo "- **Contexto NO proporcionado:** $CONTEXT_NO ($((CONTEXT_NO * 100 / TOTAL_ERRORS))%)" >> "$REPORT_FILE"

# Iteraciones promedio con/sin contexto
AVG_WITH_CONTEXT=$(jq -r 'select(.context_provided == true) | .iterations' "$FEEDBACK_FILE" | awk '{sum+=$1; cnt++} END {printf "%.2f", sum/cnt}')
AVG_WITHOUT_CONTEXT=$(jq -r 'select(.context_provided == false) | .iterations' "$FEEDBACK_FILE" | awk '{sum+=$1; cnt++} END {printf "%.2f", sum/cnt}')
echo "- **Promedio iteraciones CON contexto:** $AVG_WITH_CONTEXT" >> "$REPORT_FILE"
echo "- **Promedio iteraciones SIN contexto:** $AVG_WITHOUT_CONTEXT" >> "$REPORT_FILE"

echo "" >> "$REPORT_FILE"

# 6. Patrones cr√≠ticos (>10 ocurrencias)
echo "## 6. PATRONES CR√çTICOS (‚â•10 ocurrencias)" >> "$REPORT_FILE"
echo "" >> "$REPORT_FILE"

jq -r '.error_category' "$FEEDBACK_FILE" | sort | uniq -c | sort -rn | while read count category; do
    if [ "$count" -ge 10 ]; then
        echo "### ‚ö†Ô∏è $category ($count ocurrencias)" >> "$REPORT_FILE"
        echo "" >> "$REPORT_FILE"
        echo "**Ejemplos de errores:**" >> "$REPORT_FILE"
        jq -r "select(.error_category == \"$category\") | .error_detail" "$FEEDBACK_FILE" | head -5 | while read detail; do
            echo "- $detail" >> "$REPORT_FILE"
        done
        echo "" >> "$REPORT_FILE"

        # Archivos m√°s afectados
        echo "**Archivos m√°s afectados:**" >> "$REPORT_FILE"
        jq -r "select(.error_category == \"$category\") | .archivo_afectado" "$FEEDBACK_FILE" | grep -v "^$" | sort | uniq -c | sort -rn | head -3 | while read cnt file; do
            echo "- $file ($cnt veces)" >> "$REPORT_FILE"
        done
        echo "" >> "$REPORT_FILE"
    fi
done

# 7. Recomendaciones
echo "## 7. RECOMENDACIONES DE MEJORA" >> "$REPORT_FILE"
echo "" >> "$REPORT_FILE"
echo "Basado en el an√°lisis, se recomienda:" >> "$REPORT_FILE"
echo "" >> "$REPORT_FILE"

# Recomendar seg√∫n categor√≠a m√°s frecuente
TOP_CATEGORY=$(jq -r '.error_category' "$FEEDBACK_FILE" | sort | uniq -c | sort -rn | head -1 | awk '{print $2}')
TOP_COUNT=$(jq -r '.error_category' "$FEEDBACK_FILE" | sort | uniq -c | sort -rn | head -1 | awk '{print $1}')

echo "1. **Prioridad 1:** Abordar categor√≠a \`$TOP_CATEGORY\` ($TOP_COUNT ocurrencias)" >> "$REPORT_FILE"
echo "   - Revisar PROMPT-SUBAGENTES.md secci√≥n relacionada" >> "$REPORT_FILE"
echo "   - Agregar ejemplos espec√≠ficos" >> "$REPORT_FILE"
echo "   - A√±adir warnings expl√≠citos" >> "$REPORT_FILE"
echo "" >> "$REPORT_FILE"

if [ "$CONTEXT_NO" -gt "$((TOTAL_ERRORS / 4))" ]; then
    echo "2. **Prioridad 2:** Mejorar provisi√≥n de contexto" >> "$REPORT_FILE"
    echo "   - $CONTEXT_NO errores ($((CONTEXT_NO * 100 / TOTAL_ERRORS))%) ocurrieron sin contexto completo" >> "$REPORT_FILE"
    echo "   - Revisar uso de TEMPLATE-CONTEXTO-SUBAGENTE.md" >> "$REPORT_FILE"
    echo "" >> "$REPORT_FILE"
fi

if [ "$AVG_ITERATIONS" -gt 1.5 ]; then
    echo "3. **Prioridad 3:** Reducir iteraciones promedio" >> "$REPORT_FILE"
    echo "   - Actual: $AVG_ITERATIONS iteraciones promedio" >> "$REPORT_FILE"
    echo "   - Objetivo: <1.5 iteraciones" >> "$REPORT_FILE"
    echo "   - Mejorar claridad de instrucciones en prompts" >> "$REPORT_FILE"
    echo "" >> "$REPORT_FILE"
fi

echo "---" >> "$REPORT_FILE"
echo "" >> "$REPORT_FILE"
echo "**Pr√≥ximo an√°lisis:** Ejecutar despu√©s de 20 validaciones m√°s" >> "$REPORT_FILE"

# Mostrar reporte
cat "$REPORT_FILE"

echo ""
echo "‚úÖ Reporte guardado en: $REPORT_FILE"
```

**Hacer ejecutable:**

```bash
chmod +x orchestration/scripts/analyze-feedback.sh
```

**Ejecutar:**

```bash
# An√°lisis completo
./orchestration/scripts/analyze-feedback.sh

# Solo √∫ltimas N entradas
./orchestration/scripts/analyze-feedback.sh --last 50

# Filtrar por categor√≠a
./orchestration/scripts/analyze-feedback.sh --category missing_specification
```

### 2.3. Identificaci√≥n de Patrones

**Un patr√≥n cr√≠tico se identifica cuando:**

```yaml
criterios:
  - frecuencia >= 10 ocurrencias
  - porcentaje >= 15% del total
  - promedio_iteraciones >= 2.0
  - tasa_correccion < 90%
```

**Ejemplo de patr√≥n cr√≠tico:**

```markdown
## PATR√ìN CR√çTICO DETECTADO

**Categor√≠a:** missing_specification
**Frecuencia:** 18 ocurrencias en 60 validaciones (30%)
**Promedio iteraciones:** 2.3
**Tasa correcci√≥n:** 94%

**Ejemplos de errores:**
1. Falt√≥ implementar √≠ndice idx_projects_code especificado en contexto
2. No implement√≥ constraint CHECK en columna status
3. Omiti√≥ validaci√≥n @IsNotEmpty en property code
4. No cre√≥ relaci√≥n @ManyToOne especificada

**An√°lisis:**
Los subagentes est√°n leyendo el contexto pero NO est√°n verificando
que implementaron TODOS los elementos antes de reportar.

**Causa ra√≠z:**
PROMPT-SUBAGENTES.md Paso 5 (Validaci√≥n) no enfatiza suficientemente
la necesidad de crear una tabla comparativa Solicitado vs Implementado.

**Acci√≥n requerida:**
Actualizar PROMPT-SUBAGENTES.md con tabla comparativa obligatoria.
```

---

## COMPONENTE 3: IMPLEMENTACI√ìN DE MEJORAS

### 3.1. Proceso de Mejora

```mermaid
graph TD
    A[Patr√≥n detectado] --> B[Analizar causa ra√≠z]
    B --> C{¬øCu√°l es la causa?}
    C -->|Prompt poco claro| D[Actualizar prompt]
    C -->|Falta ejemplo| E[Agregar ejemplo]
    C -->|Warning ausente| F[Agregar warning]
    C -->|Checklist incompleto| G[Mejorar checklist]
    C -->|Template insuficiente| H[Mejorar template]
    D --> I[Documentar cambio]
    E --> I
    F --> I
    G --> I
    H --> I
    I --> J[Actualizar CHANGELOG]
    J --> K[Medir efectividad]
    K --> L{¬øEfectivo?}
    L -->|S√ç| M[Mantener cambio]
    L -->|NO| N[Iterar mejora]
    N --> B
```

### 3.2. Template de Mejora

**Ubicaci√≥n:** `orchestration/reportes/mejoras/MEJORA-{YYYY-MM-DD}-{N}.md`

```markdown
# MEJORA DEL SISTEMA DE SUBAGENTES

**ID:** MEJORA-2025-11-17-001
**Fecha:** 2025-11-17
**Tipo:** Actualizaci√≥n de Prompt | Nueva Directiva | Mejora de Template | Otro

---

## 1. PATR√ìN DETECTADO

**Categor√≠a de error:** {error_category}
**Frecuencia:** {N} ocurrencias en {M} validaciones ({porcentaje}%)
**Periodo:** {fecha_inicio} a {fecha_fin}
**Promedio iteraciones:** {X.X}

**Ejemplos de errores:**
1. {Ejemplo 1}
2. {Ejemplo 2}
3. {Ejemplo 3}

**Referencias:**
- An√°lisis completo: `orchestration/reportes/analisis-feedback/analisis-{timestamp}.md`
- Entradas JSONL: L√≠neas {X}-{Y} en FEEDBACK-SUBAGENTES.jsonl

---

## 2. AN√ÅLISIS DE CAUSA RA√çZ

### Causa Identificada

{Descripci√≥n detallada de por qu√© ocurre el error}

**Ejemplo:**
Los subagentes est√°n omitiendo la validaci√≥n de especificaciones completas
porque el PROMPT-SUBAGENTES.md Paso 5 solo menciona "validar localmente"
sin explicitar que deben crear una tabla comparativa de Solicitado vs Implementado.

### Evidencia

**Fragmento del prompt actual:**
```markdown
Paso 5: VALIDAR LOCALMENTE

Antes de reportar, valida que tu implementaci√≥n funciona correctamente.
```

**Problema:**
No especifica C√ìMO validar que TODAS las especificaciones fueron implementadas.

---

## 3. SOLUCI√ìN PROPUESTA

### Cambio a Implementar

**Archivo a modificar:** `{ruta del archivo}`
**Secci√≥n a modificar:** `{secci√≥n espec√≠fica}`

**Cambio propuesto:**

```markdown
ANTES:
{Contenido actual}

DESPU√âS:
{Contenido propuesto}
```

### Ejemplos Adicionales (si aplica)

Agregar los siguientes ejemplos:

```markdown
{Ejemplo 1}
{Ejemplo 2}
```

### Warnings Adicionales (si aplica)

Agregar el siguiente warning:

```markdown
‚ö†Ô∏è WARNING: {Texto del warning}
```

---

## 4. IMPLEMENTACI√ìN

### Archivos Modificados

- [ ] `orchestration/prompts/PROMPT-SUBAGENTES.md`
  - Secci√≥n modificada: {secci√≥n}
  - L√≠neas: {X-Y}
  - Tipo: {agregado/modificado/eliminado}

- [ ] `orchestration/templates/TEMPLATE-CONTEXTO-SUBAGENTE.md`
  - Secci√≥n modificada: {secci√≥n}
  - L√≠neas: {X-Y}
  - Tipo: {agregado/modificado/eliminado}

### Diff de Cambios

```diff
{Git diff de los cambios realizados}
```

---

## 5. DOCUMENTACI√ìN DEL CAMBIO

### Actualizar CHANGELOG

```markdown
## {Fecha} - v{X.Y.Z}

### Mejoras
- **{Archivo}**: {Descripci√≥n del cambio}
  - Raz√≥n: {Categor√≠a de error} - {N} ocurrencias ({porcentaje}%)
  - Resultado esperado: Reducir a <{objetivo}%
  - Referencias: MEJORA-{YYYY-MM-DD}-{N}

### Errores Corregidos
- {Categor√≠a}: {N} ocurrencias ‚Üí Objetivo: <{X}
```

### Comunicar a Agentes

**Mensaje a incluir en pr√≥ximo prompt de agentes:**

```markdown
üì¢ ACTUALIZACI√ìN IMPORTANTE

Se actualiz√≥ {archivo} para prevenir error frecuente:
- Problema: {descripci√≥n breve}
- Soluci√≥n: {cambio implementado}
- Acci√≥n: Consultar nueva secci√≥n {X}
```

---

## 6. MEDICI√ìN DE EFECTIVIDAD

### M√©tricas Baseline (Antes de Mejora)

```yaml
categoria: {error_category}
frecuencia_antes: {N} ocurrencias
porcentaje_antes: {X}%
promedio_iteraciones_antes: {X.X}
periodo_medicion: {fecha_inicio} a {fecha_fin}
validaciones_totales: {M}
```

### M√©tricas Objetivo (Despu√©s de Mejora)

```yaml
objetivo_frecuencia: < {N} ocurrencias
objetivo_porcentaje: < {X}%
objetivo_iteraciones: < {X.X}
periodo_medicion: 30 d√≠as despu√©s de implementaci√≥n
```

### Plan de Seguimiento

```markdown
**Verificaci√≥n 1:** +7 d√≠as
- Revisar √∫ltimas 10 validaciones
- Calcular frecuencia de {error_category}
- ¬øMejor√≥? S√ç/NO

**Verificaci√≥n 2:** +14 d√≠as
- Revisar √∫ltimas 20 validaciones
- Calcular frecuencia de {error_category}
- ¬øAlcanz√≥ objetivo? S√ç/NO

**Verificaci√≥n 3:** +30 d√≠as
- An√°lisis completo (50+ validaciones)
- Comparar con baseline
- Decisi√≥n: MANTENER / ITERAR / REVERTIR
```

---

## 7. RESULTADOS (Completar despu√©s de seguimiento)

### Verificaci√≥n 1 (+7 d√≠as)

**Fecha:** {YYYY-MM-DD}
**Validaciones revisadas:** {N}
**Frecuencia observada:** {N} ocurrencias ({porcentaje}%)
**vs Baseline:** {+/-X}%
**Estado:** ‚úÖ Mejora / ‚ö†Ô∏è Sin cambio / ‚ùå Empeor√≥

**Comentarios:**
{Observaciones}

### Verificaci√≥n 2 (+14 d√≠as)

**Fecha:** {YYYY-MM-DD}
**Validaciones revisadas:** {N}
**Frecuencia observada:** {N} ocurrencias ({porcentaje}%)
**vs Baseline:** {+/-X}%
**Estado:** ‚úÖ Mejora / ‚ö†Ô∏è Sin cambio / ‚ùå Empeor√≥

**Comentarios:**
{Observaciones}

### Verificaci√≥n Final (+30 d√≠as)

**Fecha:** {YYYY-MM-DD}
**Validaciones revisadas:** {N}
**Frecuencia observada:** {N} ocurrencias ({porcentaje}%)
**vs Baseline:** {+/-X}%
**Objetivo alcanzado:** ‚úÖ S√ç / ‚ùå NO

**Comentarios:**
{Observaciones}

**Decisi√≥n:**
- [ ] ‚úÖ MANTENER - La mejora es efectiva
- [ ] üîÑ ITERAR - Mejor√≥ pero no alcanz√≥ objetivo
- [ ] ‚ùå REVERTIR - No tuvo efecto o empeor√≥

---

## 8. LECCIONES APRENDIDAS

### Qu√© funcion√≥ bien

{Lista de aspectos positivos}

### Qu√© no funcion√≥

{Lista de aspectos negativos}

### Pr√≥ximos pasos

{Acciones adicionales recomendadas}

---

**Estado:** üîÑ En Implementaci√≥n | üìä En Seguimiento | ‚úÖ Completado | ‚ùå Revertido
**Responsable:** {Nombre del agente o persona}
**√öltima actualizaci√≥n:** {YYYY-MM-DD}
```

### 3.3. Actualizar CHANGELOG

**Archivo:** `orchestration/CHANGELOG-SISTEMA-SUBAGENTES.md`

```markdown
# CHANGELOG - Sistema de Subagentes

Registro de mejoras al sistema de prompts, directivas y templates de subagentes.

---

## 2025-11-25 - v1.2.0

### Mejoras

- **PROMPT-SUBAGENTES.md (Paso 5)**: Agregado paso obligatorio de tabla comparativa
  - Raz√≥n: `missing_specification` - 18 ocurrencias (30%)
  - Cambio: Secci√≥n "5.2. Validaci√≥n de Especificaciones" ahora incluye tabla obligatoria
  - Resultado esperado: Reducir missing_specification de 30% a <5%
  - Referencias: MEJORA-2025-11-25-001

- **TEMPLATE-CONTEXTO-SUBAGENTE.md**: Mejoradas tablas de especificaciones
  - Raz√≥n: Contexto insuficiente causaba ambig√ºedad
  - Cambio: Agregadas columnas "Descripci√≥n" y "Ejemplo" en tablas
  - Resultado esperado: Reducir `misunderstood_context` de 12% a <5%
  - Referencias: MEJORA-2025-11-25-002

### Errores Detectados (Periodo: 2025-11-10 a 2025-11-25)

| Categor√≠a | Frecuencia | % | Acci√≥n |
|-----------|------------|---|--------|
| missing_specification | 18 | 30% | ‚úÖ Corregido v1.2.0 |
| wrong_nomenclature | 12 | 20% | ‚è≥ Pendiente v1.3.0 |
| duplicate_not_detected | 8 | 13% | üîÑ En an√°lisis |

### M√©tricas del Periodo

```yaml
validaciones_totales: 60
errores_totales: 22
tasa_aprobacion_primera_vez: 63.3%
promedio_iteraciones: 1.6
tiempo_validacion_promedio: 9.2 min

objetivos:
  tasa_aprobacion: 85% (actual: 63% ‚ùå)
  iteraciones: 1.5 (actual: 1.6 ‚ùå)
  tiempo_validacion: 10 min (actual: 9.2 ‚úÖ)
```

---

## 2025-11-18 - v1.1.0

### Mejoras

- **PROMPT-SUBAGENTES.md**: Agregadas secciones de errores comunes
  - Raz√≥n: Subagentes repet√≠an errores hist√≥ricos
  - Cambio: Secci√≥n "‚ùå ERRORES HIST√ìRICOS CR√çTICOS" con 5 errores comunes
  - Resultado: Redujo errores generales de 40% a 30%

- **TEMPLATE-CONTEXTO-SUBAGENTE.md**: Template inicial creado
  - Raz√≥n: Agentes no proporcionaban contexto estructurado
  - Resultado: Redujo `context_not_read` de 25% a 12%

### M√©tricas del Periodo

```yaml
validaciones_totales: 40
tasa_aprobacion_primera_vez: 60%
promedio_iteraciones: 1.8
```

---

## 2025-11-17 - v1.0.0

### Inicial

- Creaci√≥n del sistema de orquestaci√≥n de agentes
- PROMPT-SUBAGENTES.md v1.0.0
- DIRECTIVA-VALIDACION-SUBAGENTES.md v1.0.0
- ESTANDARES-NOMENCLATURA.md v1.0.0
- Sistema de feedback implementado

---

**Formato:** Semantic Versioning (MAJOR.MINOR.PATCH)
- MAJOR: Cambios incompatibles con versiones anteriores
- MINOR: Nuevas funcionalidades compatibles
- PATCH: Correcciones de bugs
```

---

## COMPONENTE 4: SEGUIMIENTO Y M√âTRICAS

### 4.1. Dashboard de M√©tricas

**Archivo:** `orchestration/estados/METRICAS-VALIDACION.yml`

(Ya descrito en DIRECTIVA-VALIDACION-SUBAGENTES.md)

### 4.2. Script de Actualizaci√≥n de M√©tricas

**Ubicaci√≥n:** `orchestration/scripts/update-metrics.py`

```python
#!/usr/bin/env python3
"""
Script para actualizar m√©tricas de validaci√≥n
Uso: python update-metrics.py --result approved|rejected --agent Database-Agent --time 10 --iterations 1
"""

import argparse
import yaml
import json
from datetime import datetime
from pathlib import Path

METRICS_FILE = Path("orchestration/estados/METRICAS-VALIDACION.yml")
FEEDBACK_FILE = Path("orchestration/estados/FEEDBACK-SUBAGENTES.jsonl")

def load_metrics():
    if METRICS_FILE.exists():
        with open(METRICS_FILE) as f:
            return yaml.safe_load(f)
    return {
        'version': '1.0.0',
        'ultima_actualizacion': datetime.now().isoformat(),
        'total_validaciones': 0,
        'total_aprobadas_primera_vez': 0,
        'total_rechazadas': 0,
        'tasa_aprobacion_primera_vez': 0.0,
        'por_agente': {},
        'errores_por_fase': {},
        'top_errores': [],
        'iteraciones': {'promedio': 0.0, 'minimo': 999, 'maximo': 0},
        'tiempo_validacion': {'promedio': 0.0, 'minimo': 999, 'maximo': 0},
        'objetivos': {
            'tasa_aprobacion_primera_vez': 85.0,
            'tiempo_validacion_max': 10.0,
            'iteraciones_max': 1.5
        },
        'cumplimiento_objetivos': {}
    }

def update_metrics(result, agent, time_minutes, iterations, errors=None):
    metrics = load_metrics()

    # Actualizar totales
    metrics['total_validaciones'] += 1

    if result == 'approved' and iterations == 1:
        metrics['total_aprobadas_primera_vez'] += 1
    elif result == 'rejected':
        metrics['total_rechazadas'] += 1

    # Calcular tasa de aprobaci√≥n
    if metrics['total_validaciones'] > 0:
        metrics['tasa_aprobacion_primera_vez'] = round(
            (metrics['total_aprobadas_primera_vez'] / metrics['total_validaciones']) * 100, 1
        )

    # Actualizar por agente
    if agent not in metrics['por_agente']:
        metrics['por_agente'][agent] = {
            'validaciones': 0,
            'aprobadas_primera_vez': 0,
            'rechazadas': 0,
            'tasa_aprobacion': 0.0
        }

    agent_metrics = metrics['por_agente'][agent]
    agent_metrics['validaciones'] += 1

    if result == 'approved' and iterations == 1:
        agent_metrics['aprobadas_primera_vez'] += 1
    elif result == 'rejected':
        agent_metrics['rechazadas'] += 1

    if agent_metrics['validaciones'] > 0:
        agent_metrics['tasa_aprobacion'] = round(
            (agent_metrics['aprobadas_primera_vez'] / agent_metrics['validaciones']) * 100, 1
        )

    # Actualizar iteraciones
    iter_data = metrics['iteraciones']
    total = metrics['total_validaciones']
    iter_data['minimo'] = min(iter_data['minimo'], iterations)
    iter_data['maximo'] = max(iter_data['maximo'], iterations)

    # Recalcular promedio leyendo feedback
    if FEEDBACK_FILE.exists():
        with open(FEEDBACK_FILE) as f:
            all_iterations = [json.loads(line)['iterations'] for line in f]
            iter_data['promedio'] = round(sum(all_iterations) / len(all_iterations), 1)

    # Actualizar tiempo
    time_data = metrics['tiempo_validacion']
    time_data['minimo'] = min(time_data['minimo'], time_minutes)
    time_data['maximo'] = max(time_data['maximo'], time_minutes)

    # Recalcular promedio de tiempo
    if FEEDBACK_FILE.exists():
        with open(FEEDBACK_FILE) as f:
            all_times = [json.loads(line).get('time_to_fix_minutes', 0) for line in f]
            all_times = [t for t in all_times if t > 0]
            if all_times:
                time_data['promedio'] = round(sum(all_times) / len(all_times), 1)

    # Actualizar cumplimiento de objetivos
    objetivos = metrics['objetivos']
    cumplimiento = metrics['cumplimiento_objetivos']

    cumplimiento['tasa_aprobacion'] = metrics['tasa_aprobacion_primera_vez'] >= objetivos['tasa_aprobacion_primera_vez']
    cumplimiento['tiempo_validacion'] = time_data['promedio'] <= objetivos['tiempo_validacion_max']
    cumplimiento['iteraciones'] = iter_data['promedio'] <= objetivos['iteraciones_max']

    # Actualizar timestamp
    metrics['ultima_actualizacion'] = datetime.now().isoformat()

    # Guardar
    with open(METRICS_FILE, 'w') as f:
        yaml.dump(metrics, f, default_flow_style=False, allow_unicode=True)

    print(f"‚úÖ M√©tricas actualizadas: {result} - {agent} - {iterations} iter - {time_minutes} min")
    print(f"   Tasa aprobaci√≥n: {metrics['tasa_aprobacion_primera_vez']}% (objetivo: {objetivos['tasa_aprobacion_primera_vez']}%)")
    print(f"   Iteraciones promedio: {iter_data['promedio']} (objetivo: <{objetivos['iteraciones_max']})")
    print(f"   Tiempo promedio: {time_data['promedio']} min (objetivo: <{objetivos['tiempo_validacion_max']} min)")

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--result', required=True, choices=['approved', 'rejected'])
    parser.add_argument('--agent', required=True)
    parser.add_argument('--time', type=int, required=True)
    parser.add_argument('--iterations', type=int, required=True)
    parser.add_argument('--errors', help='Comma-separated error categories')

    args = parser.parse_args()

    errors = args.errors.split(',') if args.errors else None
    update_metrics(args.result, args.agent, args.time, args.iterations, errors)
```

**Hacer ejecutable:**

```bash
chmod +x orchestration/scripts/update-metrics.py
```

**Uso:**

```bash
# Despu√©s de cada validaci√≥n
python orchestration/scripts/update-metrics.py \
    --result approved \
    --agent Database-Agent \
    --time 8 \
    --iterations 1

python orchestration/scripts/update-metrics.py \
    --result rejected \
    --agent Backend-Agent \
    --time 15 \
    --iterations 2 \
    --errors missing_specification,wrong_nomenclature
```

---

## COMPONENTE 5: REVISI√ìN PERI√ìDICA

### 5.1. Revisi√≥n Semanal (Agentes Principales)

**Cada semana, ejecutar:**

```bash
# 1. An√°lisis de feedback
./orchestration/scripts/analyze-feedback.sh

# 2. Revisar reporte generado
cat orchestration/reportes/analisis-feedback/analisis-{timestamp}.md

# 3. Identificar patrones cr√≠ticos (‚â•10 ocurrencias)

# 4. Si hay patrones, crear registro de mejora
cp orchestration/templates/TEMPLATE-MEJORA.md \
   orchestration/reportes/mejoras/MEJORA-$(date +%Y-%m-%d)-001.md

# 5. Completar template de mejora

# 6. Implementar cambios

# 7. Actualizar CHANGELOG
```

### 5.2. Revisi√≥n Mensual (Administrador del Sistema)

**Cada mes, ejecutar:**

```bash
# 1. An√°lisis completo
./orchestration/scripts/analyze-feedback.sh

# 2. Revisar m√©tricas globales
cat orchestration/estados/METRICAS-VALIDACION.yml

# 3. Revisar mejoras implementadas
ls -la orchestration/reportes/mejoras/

# 4. Evaluar efectividad de mejoras
# Para cada mejora implementada hace 30+ d√≠as:
#   - ¬øRedujo la frecuencia del error?
#   - ¬øAlcanz√≥ el objetivo?
#   - ¬øDebe iterarse o revertirse?

# 5. Actualizar CHANGELOG con resultados

# 6. Planificar mejoras para pr√≥ximo mes
```

### 5.3. Checklist de Revisi√≥n Mensual

```markdown
## REVISI√ìN MENSUAL - {YYYY-MM}

**Fecha:** {YYYY-MM-DD}
**Periodo:** {fecha_inicio} a {fecha_fin}
**Validaciones totales:** {N}

### 1. M√©tricas Globales

- [ ] Revisadas m√©tricas en METRICAS-VALIDACION.yml
- [ ] Tasa de aprobaci√≥n: {X}% (objetivo: 85%)
- [ ] Iteraciones promedio: {X.X} (objetivo: <1.5)
- [ ] Tiempo validaci√≥n: {X} min (objetivo: <10 min)

### 2. An√°lisis de Feedback

- [ ] Ejecutado script analyze-feedback.sh
- [ ] Identificados patrones cr√≠ticos (‚â•10 ocurrencias)
- [ ] Top 3 categor√≠as de errores:
  1. {categoria1}: {N} ({porcentaje}%)
  2. {categoria2}: {N} ({porcentaje}%)
  3. {categoria3}: {N} ({porcentaje}%)

### 3. Mejoras Implementadas

- [ ] Revisadas mejoras del mes pasado
- [ ] Evaluada efectividad (mejoras +30 d√≠as):
  - MEJORA-{ID}: {Efectiva/Inefectiva/En seguimiento}
  - MEJORA-{ID}: {Efectiva/Inefectiva/En seguimiento}

### 4. Nuevas Mejoras

- [ ] Creadas mejoras para patrones cr√≠ticos:
  - MEJORA-{ID}: {Categor√≠a} - {Descripci√≥n breve}
  - MEJORA-{ID}: {Categor√≠a} - {Descripci√≥n breve}

### 5. CHANGELOG

- [ ] Actualizado CHANGELOG-SISTEMA-SUBAGENTES.md
- [ ] Documentadas m√©tricas del periodo
- [ ] Documentadas mejoras implementadas

### 6. Comunicaci√≥n

- [ ] Comunicadas actualizaciones a agentes
- [ ] Actualizada documentaci√≥n si necesario

### 7. Planificaci√≥n

**Objetivos pr√≥ximo mes:**
- {Objetivo 1}
- {Objetivo 2}
- {Objetivo 3}

**Mejoras prioritarias:**
1. {Categor√≠a}: {Acci√≥n}
2. {Categor√≠a}: {Acci√≥n}
```

---

## EJEMPLOS COMPLETOS

### Ejemplo 1: Ciclo Completo de Mejora

**1. Detecci√≥n del Patr√≥n (Semana 1)**

```bash
$ ./orchestration/scripts/analyze-feedback.sh
...
## 6. PATRONES CR√çTICOS (‚â•10 ocurrencias)

### ‚ö†Ô∏è missing_specification (18 ocurrencias)

**Ejemplos de errores:**
- Falt√≥ implementar √≠ndice idx_projects_code especificado en contexto
- No implement√≥ constraint CHECK en columna status
- Omiti√≥ validaci√≥n @IsNotEmpty en property code
...
```

**2. Creaci√≥n de Registro de Mejora**

```bash
$ cp orchestration/templates/TEMPLATE-MEJORA.md \
     orchestration/reportes/mejoras/MEJORA-2025-11-25-001.md

$ vim orchestration/reportes/mejoras/MEJORA-2025-11-25-001.md
# Completar template con an√°lisis de causa ra√≠z
```

**3. Implementaci√≥n del Cambio**

```bash
$ vim orchestration/prompts/PROMPT-SUBAGENTES.md
# Agregar secci√≥n de tabla comparativa en Paso 5
```

**4. Actualizaci√≥n del CHANGELOG**

```bash
$ vim orchestration/CHANGELOG-SISTEMA-SUBAGENTES.md
# Agregar entrada de v1.2.0 con mejora
```

**5. Seguimiento (+7 d√≠as)**

```bash
# Revisar √∫ltimas 10 validaciones
$ tail -10 orchestration/estados/FEEDBACK-SUBAGENTES.jsonl | \
  jq -r 'select(.error_category == "missing_specification")'
# Resultado: 0 ocurrencias (¬°mejora!)
```

**6. Seguimiento (+30 d√≠as)**

```bash
$ ./orchestration/scripts/analyze-feedback.sh --last 50
...
| missing_specification | 2 | 4% | 1.0 |
# ¬°Baj√≥ de 30% a 4%! ‚úÖ Mejora efectiva
```

**7. Actualizaci√≥n del Registro de Mejora**

```bash
$ vim orchestration/reportes/mejoras/MEJORA-2025-11-25-001.md
# Completar secci√≥n "7. RESULTADOS" con datos de seguimiento
# Marcar como "‚úÖ MANTENER - La mejora es efectiva"
```

---

## RESPONSABILIDADES

### Agentes Principales

**SIEMPRE debes:**
- ‚úÖ Registrar TODOS los errores en FEEDBACK-SUBAGENTES.jsonl
- ‚úÖ Actualizar m√©tricas despu√©s de cada validaci√≥n
- ‚úÖ Ejecutar an√°lisis semanal de feedback
- ‚úÖ Identificar patrones cr√≠ticos
- ‚úÖ Crear registros de mejora para patrones detectados
- ‚úÖ Implementar mejoras aprobadas

### Administrador del Sistema

**SIEMPRE debe:**
- ‚úÖ Ejecutar revisi√≥n mensual completa
- ‚úÖ Evaluar efectividad de mejoras implementadas
- ‚úÖ Aprobar/rechazar propuestas de mejora
- ‚úÖ Mantener CHANGELOG actualizado
- ‚úÖ Comunicar actualizaciones a agentes

---

## CRITERIOS DE √âXITO

### A Corto Plazo (1 mes)

```yaml
objetivos:
  patrones_criticos_detectados: >= 1
  mejoras_implementadas: >= 1
  reduccion_errores: >= 20%  # Para categor√≠a mejorada
```

### A Mediano Plazo (3 meses)

```yaml
objetivos:
  tasa_aprobacion_primera_vez: >= 85%
  promedio_iteraciones: <= 1.5
  tiempo_validacion: <= 10 min
  categorias_criticas_resueltas: >= 3
```

### A Largo Plazo (6 meses)

```yaml
objetivos:
  tasa_aprobacion_primera_vez: >= 95%
  promedio_iteraciones: <= 1.2
  errores_duplicados: 0
  prompts_estables: true  # Sin necesidad de cambios frecuentes
```

---

## REFERENCIAS

- [DIRECTIVA-VALIDACION-SUBAGENTES.md](./DIRECTIVA-VALIDACION-SUBAGENTES.md) - Proceso de validaci√≥n
- [PROMPT-SUBAGENTES.md](../prompts/PROMPT-SUBAGENTES.md) - Prompt de subagentes
- [CHANGELOG-SISTEMA-SUBAGENTES.md](../CHANGELOG-SISTEMA-SUBAGENTES.md) - Historial de mejoras

---

**Versi√≥n:** 1.0.0
**√öltima actualizaci√≥n:** 2025-11-17
**Uso:** Obligatorio para mantener y mejorar el sistema de subagentes
